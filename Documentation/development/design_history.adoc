Certainly! Here's the provided text formatted in ASCII Doc:


= Entwurf 1 =

https://github.com/tBuddy00/Follow-Me-Roboter/blob/main/Documentation/architecture/konzept%20v2.pdf

Der erste Entwurf Endstand noch bevor dem ersten Kunden Meeting und diente dabei als Vorbereitung für dieses es geht dabei um ein Basis Konzept.

= Entwurf 2 =

== Vorgaben ==
* Verwendung von Ros
	** Mit Ros ist die grundlegende Struktur unserer Software fest fortgegeben. Ros2 ist in einem Paket System Strukturiert in welches aus mehreren Nodes besteht (den eigentlichen Software Komponenten)
* Verwendung des Alphabots 2
	** Die Verwendung des Alphabots bringt vor allem Hardware

== Technische Entscheidung ==
* Verwendung eines Vorgefertigtem Linux images mit Ros vorinstaliert
	** Image: Ubiquity Robotics raspberry pi image https://learn.ubiquityrobotics.com/noetic_pi_image_downloads
	** Pro:
		*** Die Verwendung eines Images erspart viel zeit im initialem Setup des Systems
		*** Ros funktioniert out of the box
		*** Es ist Scheller möglich Tests auszuführen
	** Contra:
		*** Weniger customisation
* Verwendung des ROS for Waveshare Alphabot2 Repository https://github.com/ShaunPrice/ROS_for_Waveshare_Alphabot2
	** Pro:
		*** Das Repository ist voll entwickelt und kompatibel mit unserem Linux Image
		*** Ist Speziel geschrieben für den Alphabot
	** Contra:
		*** Ist Mittlerweile 5 Jahre alt

Da dieser Entwurf im Ramen der Testphase entstand sind noch keine konkreteren Strukturen entstanden

= Entwurf 3 =

== Bild: Program Desing ==
== Änderung zum letzten Entwurf ==
* Das ROS for Waveshare Alphabot2 Repository kann in der aktuellen form nicht verwendet werden da es für Ros 1 geschrieben ist was auf Python 2. das Problem mit Python 2 ist das es kurz davor steht nicht mehr unterstützt zu werden somit sind viele modernere Features nicht verfügbar.
Somit umstieg auf Ros2
* Das Linux Image wird nicht mehr verwendet da es auf einer veralteten Linux Version basiert welche nicht mit Ros2 kompatiebel ist

== Technische Entscheidung ==
* Verwendung von Ros2 Humble
	** Pro:
		*** Ros2 humble ist eine der neusten Ros2 Versionen
		*** es gibt eine Vielzahl an Software
		*** vielen Systemen unterstützt Ros2
		*** Umfangreiche Dokumentation
	** Contra:
		*** Ros2 ist im allgemeinen recht komplex und hat somit eine recht lange einarbeitungszeit
* Verwendung von Ubuntu Server 22.04.03 LTS (64 bit)
	** Pro:
		*** Ist das zu Ros2 humble empfohlene Operating System
		*** Ist kompatiebel mit einer vielzahl an software
		*** Eine der Aktuelsten Ubuntu versionen
	** Contra:
		*** Hat keine grafische Benutzeroberfläche
* Verwendung von Python als Programmiersprache
	** Pro:
		*** Python ist eine von 2 Sprachen die mit Ros2 Kompatibel sind und ist dabei deutlich einfacher zu implementieren als die Alternative C++
	** Contra:
		*** Man kann in Ros2 mit Python keine Message Formate erstellen und ist somit an die Standard Formate gebunden
* Übersetzung des ROS for Waveshare Alphabot2 Repository von Ros1 in Ros2
	** Pro:
		*** Die Repo liefert eine gute Grundlage um zu verstehen wie Ros Systeme allgemein aufgebaut sind
		*** Sie enthält eine Vielzahl von Informationen Speziell zum Alphabot2
	** Contra:
		*** Teilweise zu komplex für unseren anwendungsfall
* Verwendung der ros2_v4ls_camera https://github.com/tier4/ros2_v4l2_camera/tree/galactic Kammera node
	** Es wurde eine Vielzahl an Kammera nodes Probiert die meisten sind aber für Rasbian geschrieben und funktionieren mit unserem system nicht
	** Pro:
		*** Funktioniert mit dem System
		*** Ist einfach zu installieren
	** Contra:
		*** Schwer konfigurierbar
* Verwendung von CV Bridge
	** Pro:
		*** Ermöglicht die einfache umwandlung vom Ros2 image format in das open cv Image format

== Strukturelle Entscheidungen ==
* Das Modell Zeigt den allgemeinen Aufbau des Systems
* Dabei gibt es eine Node für jede hardware componente des Alphabot2 welche mittels messages angesteuert werden kann
* Weiter gibt es die cammera_subscriber node welche das empfangen und auswerten der bilder übernimt
* Und die movement_control Node welche die ausgewerteten daten empfängt und in signale für die Nodes umwandelt welche die Hardware Komponenten Steuern

= Entwurf 4 =

== Bild: Desing_v2 ==
== Änderung zum letzten Entwurf ==
* Leichte Änderung des Strukturellen Aufbaus

== Strukturelle Entscheidungen ==
* Aufteilung des Sytems in 2 Packages
	** Diese Entscheidung wurde getroffen Um das system möglichst modular zu gestalten
	** Das ros2_for_waveshare Package ist dabei speziel für den Alphabot2 geschrieben und somit eine art update des ROS for Waveshare Alphabot2 Repository. Die idee ist dabei das das Package unabhängig von unserem System mit dem Alphabot2 verwendet werden kann
	** Das cammera_package enthelt dabei Sämtliche tolls zur bildverarbeitung und berechnung der imput signale. Da es unabhängig vom ersten package funktioniert könte man in der zukunft z.B. recht einfach auf eine andere Plattform umsteigen ohne den code stark zu modifizieren
* Johan infos zu human detecktor ergänzen

Entwurf 4 ist der erste funktionale Entwurf und auch der erste Entwurf mit einem Prototypen

= Entwurf 5 =

== Bild: Desing_v4-Software overview ==
== Technische Entscheidung ==
* Hinzufügen einer web Oberfläche welche die vom human_detector bearbeiteten Bilder anzeigt
	** Pro:
		*** Das Tool ermöglicht es zu sehen Wie gut das Tracking funktioniert und ist somit unbedingt notwending für debuging
	** Contra:
		*** Performance Verlust
* Verwendung von flask für das web tool
	** Pro:
		*** Relative einfache Implementierung in Python
	** Contra:
		*** Teilweise Kompatibilität Probleme mit Ros2
	    *** Muss in einem seperaten Thread laufen da es sonst Probleme mit Ros2 gibt
		*** Erhöter Performance gebrauch durch Threading

Durch die implementation des camera_streamers war es deutliche einfacher zu vertehen wie gut die erkennung funktioniert somit ist uns auch ein großes Problem aufgefallen die bis jetzt Verwednete Kammera hat einen viel zu geringen winkel für unseren anwendungsfall da person ungefär 3m vom Robotter entfernt stehen müssen um Überhaupt volständig im bild erkant zu werden
Zudem ist der Bilderkeenungs algorythmus den wir verwenden recht ungenau und erkennt personen entweder nicht oder erkent personen in gegenständen

= Entwurf 5 =

== Bild: ==
== Änderung zum letzten Entwurf ==
* Wegfall der ros2_v4ls_camera Node
* Austauch der auf dem Alphabot2 vorinstallierten Kammera durch eine USB Kammera
	** Da die Vorinstalierte Kammera nicht für unsere Zwecke ausreicht
* Wegfall der Servos
	** Die neue Kammera ist zu schwer für die Servos die dafür gebaute Softwear bleibt trotzdem im projekt für eventuelle spätere benutzung

== Technische Entscheidung ==
* Wechsel auf eine USB Kammera
	** Pro:
		*** Bessere Qualität und ein deutlich größerer winkel
	** Contra:
		*** Deutlich schwerer deshalb wegfall der servos
		*** Höherer Stromverbrauch
* Wechsel auf die Opencv Video Stream capture funktion
	** Pro:
		*** Direcktes ansprechen der Kammera in Python möglich
	** Contra:
		*** Capturing findet Permanent stadt und komt somit mit einem gewissen maß an Performance Verbrauch
		*** Die Kammera can nur im Rahmen einer node verwendet werden
* Wechsel auf YOLO
	** Pro:
		*** Bessere Erkennungs Genauigkeit
	** Contra:
		*** Hoher Performance verbrauch
		*** Ziemlich langsam

Zum aktuellen Zeitraum ist noch nicht klar ob wir YOLO einsetzen können da es aktuell viel zu langsam ist die aktuelle tendenz liegt bei nein
