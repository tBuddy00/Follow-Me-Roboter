:figure-caption: Abbildung
:development-images: images
:architecture-images: ../architecture/images

== Entwurf 1

.Basiskonzept
image::{architecture-images}/konzept v2.png[]

Der erste Projektentwurf entstand noch vor dem ersten Kundenmeeting und diente dabei als Vorbereitung. Hierbei ging es im allgemeinen um ein Basiskonzept und die bessere Visualisierung für den Auftraggeber.

== Entwurf 2

=== Vorgaben

* Verwendung von ROS
    ** Mit ROS ist die grundlegende Struktur unserer Software festgelegt. ROS 2 ist in einem Paket-System strukturiert, welches aus mehreren Nodes besteht (den eigentlichen Softwarekomponenten).
* Verwendung des Alphabot 2
    ** Die Verwendung des Alphabots bringt vor allem Hardware-Anforderungen mit sich

=== Technische Entscheidung

* Verwendung eines vorgefertigten Linux-Images (mit ROS vorinstalliert)
    ** Image: Ubiquity Robotics Raspberry Pi Image https://learn.ubiquityrobotics.com/noetic_pi_image_downloads
    ** Pro:
        *** die Verwendung eines Images spart viel Zeit beim initialen Setup des Systems
        *** ROS funktioniert out of the box
        *** Tests können schneller durchgeführt werden
    ** Contra:
        *** weniger Anpassungsmöglichkeiten
* Verwendung des ROS for Waveshare Alphabot2 Repository https://github.com/ShaunPrice/ROS_for_Waveshare_Alphabot2
    ** Pro:
        *** das GitHub-Repository ist voll entwickelt und kompatibel mit unserem Linux-Image
        *** es ist speziell für den Alphabot geschrieben
    ** Contra:
        *** es ist mittlerweile 5 Jahre alt

Dieser Entwurf entstand im Rahmen der Testphase und so sind noch keine konkreteren Strukturen entstanden.

== Entwurf 3

.Systemarchitekturdiagramm  für Entwurf 3
image::{development-images}/Design_Entwurf_3.png[]
_(Abbildung 2 entspricht keinen Modellierungsstandarts und ist eher als Vorentwurf zu betrachten.)_

=== Änderung zum letzten Entwurf

* Das ROS für Waveshare Alphabot2 Repository kann in der aktuellen Form nicht verwendet werden, da es für ROS 1 geschrieben ist, welches auf Python 2 basiert. Das Problem mit Python 2 ist, dass es bald nicht mehr unterstützt wird. Dadurch sind viele modernere Features nicht verfügbar - somit ein Umstieg auf ROS 2 nötig.
* Das Linux-Image wird nicht mehr verwendet, da es auf einer veralteten Linux-Version basiert, welche nicht mit ROS 2 kompatibel sind

=== Technische Entscheidung 

* Verwendung von ROS 2 Humble
    ** Pro:
        *** ROS 2 Humble ist eine der neuesten ROS 2 Versionen
        *** es gibt eine Vielzahl an Software
        *** viele Systeme unterstützen ROS 2
        *** umfangreiche Dokumentation
    ** Contra:
        *** ROS 2 ist im Allgemeinen recht komplex und hat daher eine lange Einarbeitungszeit
* Verwendung von Ubuntu Server 22.04.03 LTS (64 Bit)
    ** Pro:
        *** das zu ROS 2 Humble empfohlene Operating-System
        *** es ist kompatibel mit einer Vielzahl an Software
        *** eine der aktuellsten Ubuntu-Versionen
    ** Contra:
        *** es hat keine grafische Benutzeroberfläche
* Verwendung von Python als Programmiersprache
    ** Pro:
        *** Python ist eine von zwei Sprachen, die mit ROS 2 kompatibel sind und deutlich einfacher zu implementieren als die Alternative C++
    ** Contra:
        *** mit Python kann man in ROS 2 keine eigenen Nachrichtenformate erstellen und ist daher an die Standardformate gebunden
* Übersetzung des ROS for Waveshare Alphabot2 Repository von ROS 1 in ROS 2
    ** Pro:
        *** das Repository liefert eine gute Grundlage, um zu verstehen, wie ROS Systeme allgemein aufgebaut sind
        *** es enthält eine Vielzahl von Informationen speziell zum Alphabot2
    ** Contra:
        *** Tteilweise zu komplex für unseren Anwendungsfall
* Verwendung der ROS2_v4ls_camera https://github.com/tier4/ros2_v4l2_camera/tree/galactic Camera Node
    ** es wurde eine Vielzahl an Kamera-Nodes ausprobiert, die meisten sind jedoch für Raspbian geschrieben und funktionieren nicht mit unserem System
    ** Pro:
        *** funktioniert mit dem System
        *** ist einfach zu installieren
    ** Contra:
        *** schwer zu konfigurieren
* Verwendung von CV Bridge
    ** Pro:
        *** ermöglicht die einfache Umwandlung vom ROS 2-Image-Format in das OpenCV-Image-Format

=== Strukturelle Entscheidungen

* das Modell zeigt den allgemeinen Aufbau des Systems.
* es gibt eine Node für jede Hardwarekomponente des Alphabot 2, welche mittels Messages angesteuert werden kann.
* des Weiteren gibt es die camera_subscriber_node, welche das empfangen und Auswerten der Bilder übernimmt.
* ebenfalls die movement_control-Node, welche die ausgewerteten Daten empfängt und in Signale für die Nodes umwandelt, die die Hardware-Komponenten steuern.

== Entwurf 4

.Systemarchitekturdiagramm  für Entwurf 4
image::{development-images}/Design_Entwurf_4.png[]
_Entwurf 4 ist der erste funktionale Entwurf und auch der erste Entwurf mit einem Prototyp. (Abbildung 3 entspricht keinen Modellierungsstandarts und ist eher als Vorentwurf zu betrachten.)_

=== Änderung zum letzten Entwurf

* leichte Änderung des strukturellen Aufbaus

=== Strukturelle Entscheidungen

* Aufteilung des Systems in zwei Pakete.
    ** diese Entscheidung wurde getroffen, um das System möglichst modular zu gestalten.
    ** das ros2_for_waveshare-Paket ist speziell für den Alphabot 2 geschrieben und stellt somit eine Art Update des ROS for Waveshare Alphabot 2-Repositories dar. Die Idee ist, dass das Paket unabhängig von unserem System mit dem Alphabot 2 verwendet werden kann.
    ** das camera_package enthält alle Tools zur Bildverarbeitung und Berechnung der Eingangssignale. Da es unabhängig vom ersten Paket funktioniert, könnte man in der Zukunft z. B. recht einfach auf eine andere Plattform umsteigen, ohne den Code stark zu modifizieren.

* *->Johan soll Informationen zum Human Detector ergänzen.*


== Entwurf 5

.Systemarchitekturdiagramm für Entwurf 5
image::{development-images}/Design_Entwurf_5.png[]
_Abbildung 4 entspricht keinen Modellierungsstandarts und ist eher als Vorentwurf zu betrachten._

=== Technische Entscheidung

* Hinzufügen einer Web-Oberfläche, die die vom human_detector bearbeiteten Bilder anzeigt
    ** Pro:
        *** das Tool ermöglicht es zu sehen, wie gut das Tracking funktioniert und ist somit unbedingt notwendig für das debugging.
    ** Contra:
        *** Performanceverlust
* Verwendung von Flask für das Web-Tool
    ** Pro:
        *** relativ einfache Implementierung in Python
    ** Contra:
        *** teilweise Kompatibilitätsprobleme mit ROS 2
        *** muss in einem separaten Thread laufen, da es sonst Probleme mit ROS 2 gibt
        *** erhöhter Performancegebrauch durch threading

Durch die Implementierung des camera_streamers war es deutlich einfacher zu verstehen, wie gut die Erkennung funktioniert. Somit ist uns auch ein großes Problem aufgefallen: Die bisher verwendete Kamera hat einen viel zu geringen Winkel für unseren Anwendungsfall, da Personen ungefähr drei Meter vom Roboter entfernt stehen müssen, um überhaupt vollständig im Bild erkannt zu werden.
Zudem ist der Bilderkennungsalgorithmus, den wir verwenden, recht ungenau und erkennt Personen entweder nicht oder erkennt Personen in Gegenständen.

== Entwurf 6

.C4-Context Entwurf 6
image::{development-images}/Desing_Entwurf_6_C4_Context.png[]
.C4-Container Entwurf 6
image::{development-images}/Desing_Entwurf_6_C4_Container.png[]
.C4-Component Entwurf 6
image::{development-images}/Desing_Entwurf_6_C4_Component.png[]


=== Änderung zum letzten Entwurf

* Entfernung der ros2_v4ls_camera-Node
* Austausch der vorinstallierten Kamera auf dem Alphabot2 durch eine USB-Kamera
    ** Da die vorinstallierte Kamera nicht für unsere Zwecke ausreicht
* Entfernung der Servos
    ** die neue Kamera ist zu schwer für die Servos; die dafür gebaute Software bleibt trotzdem im Projekt für eine eventuell spätere Benutzung.

=== Technische Entscheidung

* Wechsel zu einer USB-Kamera
    ** Pro:
        *** bessere Qualität und ein deutlich größerer Winkel
    ** Contra:
        *** deutlich schwerer, deshalb Entfernung der Servos
        *** höherer Stromverbrauch
* Wechsel zur OpenCV-Video-Stream-Capture-Funktion
    ** Pro:
        *** direktes Ansprechen der Kamera in Python möglich
    ** Contra:
        *** capturing findet permanent statt und kommt somit mit einem gewissen Maß an Performanceverbrauch
        *** die Kamera kann nur im Rahmen einer Node verwendet werden
* Wechsel zu YOLO
    ** Pro:
        *** bessere Erkennungsgenauigkeit
    ** Contra:
        *** hoher Performanceverbrauch
        *** recht langsam

Zum aktuellen Zeitpunkt ist noch nicht klar, ob wir YOLO einsetzen können, da es derzeit viel zu langsam ist - die aktuelle Tendenz liegt bei nein.

== Entwurf 7 - Prototyp 2

_Abbildung 8 entspricht keinen Modellierungsstandarts und ist eher als Vorentwurf zu betrachten._

.Systemarchitekturdiagramm  für Entwurf 7
image::{development-images}/design_Entwurf_7.png[]

.C4-Context Entwurf 7
image::{development-images}/Design_Entwurf_7_C4_Context.drawio.png[]
.C4-Container Entwurf 7
image::{development-images}/Design_Entwurf_7_C4_Container.drawio.png[]
.C4-Component Entwurf 7
image::{development-images}/Design_Entwurf_7_C4_Component.drawio.png[]
.Sequenzdiagramm Entwurf 7
image::{development-images}/Desing_Entwurf_7_Sequenzdiagram.png[]


=== Änderung zum letzten Entwurf

* Wechsel von Raspberry Pi 4 auf Nvidia Jetson Nano
    **der Raspberry Pi 4 hat nicht genug Leistung für YOLO geboten
* Wechsel von Alphabot 2 auf Arduino Uno und Adafruit Motor Shield v2.3
    ** der Alphabot 2 ist zu klein, um den Jetson Nano zu tragen
    ** der Alphabot 2 ist schlecht erweiterbar
* Entfernung des ros2_for_waveshare_alphabot2-Pakets
    ** wird nicht mehr benötigt
* Wechsel zum Jetson Nano - Ubuntu 20.04-Image
    ** der Jetson Nano hat aktuell keine offizielle Unterstützung für Ubuntu 22.04

=== Technische Entscheidung

* Wechsel zum Nvidia Jetson Nano
    ** Pro:
        *** deutlich mehr Leistung als der Raspberry Pi 4
        *** bessere Unterstützung für YOLO
    ** Contra:
        *** höherer Stromverbrauch
        *** höheres Gewicht
* Wechsel zum Arduino Uno und Adafruit Motor Shield v2.3
    ** Pro:
        *** bessere Erweiterbarkeit
        *** deutlich einfachere Motorensteuerung
        *** Testung ohne den Jetson Nano möglich, über serielle Schnittstelle
    ** Contra:
        *** Kommunikation muss über serielle Schnittstellen stattfinden
        *** komplexere Systemstruktur
* Wechsel auf Jetson Nano - Ubuntu 20.04 image
    ** Pro:
        *** offizielle Unterstützung
        *** bessere Kompatibilität
    ** Contra:
        *** ältere Ubuntu Version
        *** weniger Software verfügbar
